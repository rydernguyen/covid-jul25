{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility\n",
    "import urllib\n",
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "#Data Science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Google API\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage # Imports the Google Cloud storage library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = 'local' #local or cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if deployment == 'cloud':\n",
    "    from pyspark.sql import SparkSession #ONlY FOR CLOUD DEPLOYMENT\n",
    "    #Start spark session\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"com.google.cloud.spark:spark-bigquery-with-dependencies_2.11:0.17.0\")\\\n",
    "        .master('yarn') \\\n",
    "        .appName('spark-bigquery-ryder') \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    #Instantiate BigQuery client\n",
    "    bigquery_client = bigquery.Client() # Instantiates a client\n",
    "    #Instantiate Storage client\n",
    "    storage_client = storage.Client() # Instantiates a client\n",
    "    \n",
    "else:\n",
    "    #Set credentials for bigquery !FOR LOCAL ONLY, DON'T COPY TO PYSPARK\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"covid-jul25-**************.json\"\n",
    "    bigquery_client = bigquery.Client() # Instantiates a client\n",
    "\n",
    "    #Set credentials for cloud storage\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"covid-jul25-**************.json\"\n",
    "    storage_client = storage.Client() # Instantiates a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set working environment\n",
    "PROJECT_ID='covid-jul25'\n",
    "REGION='us-west3'\n",
    "ZONE='us-west3-a'\n",
    "BUCKET_LINK='gs://us-west3-{BUCKET_NAME}'\n",
    "BUCKET='us-west3-{BUCKET_NAME}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE STATE DATA ON BIGQUERY FOR REFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclusion lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exclude certain states\n",
    "excludestate = ['American Samoa','United States Virgin Islands','Commonwealth of the Northern Mariana Islands','Guam','Puerto Rico']\n",
    "excludestateabbr = ['AS','VI','MP','GU','PR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countyarea table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|█████████████████████████████████████████████████████████████| 3233/3233 [00:00<00:00, 3978.58rows/s]\n"
     ]
    }
   ],
   "source": [
    "#Construct countyarea\n",
    "query_job = bigquery_client.query(\n",
    "    \"\"\"\n",
    "    DROP TABLE IF EXISTS `covid-jul25.usprojections.countyarea`;\n",
    "    CREATE TABLE `covid-jul25.usprojections.countyarea` AS\n",
    "    (SELECT DISTINCT region_code, division_code, A.state_fips_code, state_name, state_abbreviation , county_name, concat(int_point_lat,',',int_point_lon) as lat_long, concat(state_name,'-',county_name) as statecounty\n",
    "    FROM `bigquery-public-data.utility_us.us_states_area` as A\n",
    "    RIGHT JOIN\n",
    "    (SELECT DISTINCT county_name, state_fips_code,\n",
    "    int_point_lat, int_point_lon,\n",
    "    FROM `bigquery-public-data.geo_us_boundaries.counties`) as B\n",
    "    ON A.state_fips_code = B.state_fips_code)\n",
    "    \"\"\"\n",
    ")\n",
    "results = query_job.result()  # Waits for job to complete.\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT *\n",
    "    FROM [covid-jul25.usprojections.countyarea]\n",
    "\"\"\"\n",
    "countyarea = pd.read_gbq(sql, dialect='legacy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State abbrev list\n",
    "stateabbrlist = countyarea.loc[:,['state_name','state_abbreviation']].drop_duplicates()\n",
    "statelist = stateabbrlist[~stateabbrlist['state_name'].isin(excludestate)]['state_name'].to_list()\n",
    "stateabb = stateabbrlist[~stateabbrlist['state_abbreviation'].isin(excludestateabbr)]['state_abbreviation'].to_list()\n",
    "\n",
    "statedict = dict(zip(stateabb, statelist))\n",
    "rstatedict = dict(zip(statelist,stateabb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write excluded list back to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.79s/it]\n"
     ]
    }
   ],
   "source": [
    "#Excluding some states\n",
    "countyarea = countyarea[~countyarea['state_name'].isin(excludestate)]\n",
    "#Add region ISO\n",
    "countyarea['region'] = 'US-' + countyarea['state_abbreviation']\n",
    "#Write back to BigQuery\n",
    "countyarea.to_gbq('usprojections.countyarea',if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE RT RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from https://rt.live/ and create rt_temp table for update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read to frame the data for rt\n",
    "rtdf = pd.read_csv('https://d14wlfuexuxgcm.cloudfront.net/covid/rt.csv')\n",
    "#Adding update time\n",
    "rtdf['update_time']=datetime.datetime.now()\n",
    "#Put region in ISO format\n",
    "rtdf['region'] = 'US-'+ rtdf['region']\n",
    "rtdf.to_gbq('usprojections.temp_rt',if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup script to recreate table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #RECREATE THE RT_RESULTS TABLE IF NEEDS TO\n",
    "# DROP TABLE IF EXISTS `covid-jul25.usprojections.rt_results`;\n",
    "# CREATE TABLE `covid-jul25.usprojections.rt_results` AS\n",
    "# SELECT * except(date), cast(date as date) as date FROM `covid-jul25.usprojections.temp_rt`\n",
    "\n",
    "# #LATEST RESULTS\n",
    "# DROP TABLE IF EXISTS `covid-jul25.usprojections.latest_rt_results`;\n",
    "# CREATE TABLE `covid-jul25.usprojections.latest_rt_results` AS\n",
    "# (SELECT * except(row) FROM\n",
    "# (SELECT * except(date), cast(date as date) as date, row_number() OVER(PARTITION BY region ORDER BY cast(date as date) DESC) row\n",
    "# FROM `covid-jul25.usprojections.temp_rt`)\n",
    "# WHERE row = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the static rt_results table using temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bigquery_client.query(\n",
    "\"\"\"\n",
    "#ALL rt\n",
    "DELETE FROM `covid-jul25.usprojections.rt_results` WHERE True;\n",
    "INSERT INTO `covid-jul25.usprojections.rt_results`\n",
    "SELECT * except(date), cast(date as date) as date FROM `covid-jul25.usprojections.temp_rt`;\n",
    "\n",
    "#ONLY latest rt\n",
    "DELETE FROM `covid-jul25.usprojections.latest_rt_results` WHERE True;\n",
    "INSERT INTO `covid-jul25.usprojections.latest_rt_results`\n",
    "(SELECT * except(row) FROM\n",
    "(SELECT * except(date), cast(date as date) as date, row_number() OVER(PARTITION BY region ORDER BY cast(date as date) DESC) row\n",
    "FROM `covid-jul25.usprojections.temp_rt`)\n",
    "WHERE row = 1);\n",
    "\"\"\")\n",
    "results = query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the static rt_duration table with ranking and more metrics days over rt of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bigquery_client.query(\n",
    "    \"\"\"\n",
    "    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.rt_duration`\n",
    "    -- CREATE TABLE `covid-jul25.usprojections.rt_duration` AS\n",
    "    DELETE FROM `covid-jul25.usprojections.rt_duration` WHERE True;\n",
    "    INSERT INTO `covid-jul25.usprojections.rt_duration`\n",
    "    SELECT mean as d_mean , median as d_median, lower_80 as d_lower_80, upper_80 as d_upper_80, M.max_date as date, M.* except(max_date), 'latest' as type,\n",
    "    RANK() OVER(ORDER BY mean DESC) rank\n",
    "    FROM `covid-jul25.usprojections.rt_results` as S\n",
    "    RIGHT JOIN\n",
    "    (SELECT MAX(date) as max_date, MIN(date) as min_date, DATE_DIFF(MAX(date),MIN(date),DAY)+1 as duration, region,\n",
    "    SUM(CASE WHEN mean < 1 THEN 0 ELSE 1 END)/(DATE_DIFF(MAX(date),MIN(date),DAY)+1) as rt_over_ratio, \n",
    "    SUM(CASE WHEN mean < 1 THEN 1 ELSE 0 END)/(DATE_DIFF(MAX(date),MIN(date),DAY)+1) as rt_under_ratio,\n",
    "    SUM(CASE WHEN mean < 1 THEN 0 ELSE 1 END) as rt_over,\n",
    "    SUM(CASE WHEN mean < 1 THEN 1 ELSE 0 END) as rt_under\n",
    "    FROM `covid-jul25.usprojections.rt_results`\n",
    "    GROUP BY region) as M\n",
    "    ON S.region = M.region\n",
    "    AND S.date = M.max_date\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT mean as d_mean , median as d_median, lower_80 as d_lower_80, upper_80 as d_upper_80, M.min_date as date, M.* except(min_date), 'earliest' as type,\n",
    "    RANK() OVER(ORDER BY mean DESC) rank\n",
    "    FROM `covid-jul25.usprojections.rt_results` as S\n",
    "    RIGHT JOIN\n",
    "    (SELECT MAX(date) as max_date, MIN(date) as min_date, DATE_DIFF(MAX(date),MIN(date),DAY)+1 as duration, region,\n",
    "    SUM(CASE WHEN mean < 1 THEN 0 ELSE 1 END)/(DATE_DIFF(MAX(date),MIN(date),DAY)+1) as rt_over_ratio, \n",
    "    SUM(CASE WHEN mean < 1 THEN 1 ELSE 0 END)/(DATE_DIFF(MAX(date),MIN(date),DAY)+1) as rt_under_ratio,\n",
    "    SUM(CASE WHEN mean < 1 THEN 0 ELSE 1 END) as rt_over,\n",
    "    SUM(CASE WHEN mean < 1 THEN 1 ELSE 0 END) as rt_under\n",
    "    FROM `covid-jul25.usprojections.rt_results`\n",
    "    GROUP BY region) as M\n",
    "    ON S.region = M.region\n",
    "    AND S.date = M.min_date\n",
    "    \"\"\")\n",
    "results = query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE CASE NUMBERS FROM JOHNS HOPKINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import confirmed, deaths and recovered cases from url\n",
    "confirmed = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\")\n",
    "deaths = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\")\n",
    "recovered = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the dataframe for export to bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formating confirmed as df ready for import for maindf\n",
    "df = confirmed.copy()\n",
    "xlist = ['UID', 'iso2', 'iso3', 'code3','Country_Region', 'Lat', 'Long_','Combined_Key']\n",
    "\n",
    "df['Lookup'] = df['Admin2'] + df['Province_State']\n",
    "includelist = [x for x in df.columns if x not in xlist]\n",
    "datelist = includelist.copy()\n",
    "datelist.pop(0)\n",
    "datelist.pop(0)\n",
    "datelist.remove('Lookup')\n",
    "df = df.loc[:,includelist]\n",
    "\n",
    "#Transpose and change index\n",
    "lookuplist = df['Lookup'].to_list()\n",
    "df = df.transpose()\n",
    "df.columns = lookuplist\n",
    "df = df.transpose()\n",
    "\n",
    "#Formating deaths as df1 ready for import for maindf\n",
    "df1 = deaths.copy()\n",
    "xlist = ['UID', 'iso2', 'iso3', 'code3','Country_Region', 'Lat', 'Long_','Combined_Key']\n",
    "\n",
    "df1['Lookup'] = df1['Admin2'] + df1['Province_State']\n",
    "includelist = [x for x in df1.columns if x not in xlist]\n",
    "datelist = includelist.copy()\n",
    "datelist.pop(0)\n",
    "datelist.pop(0)\n",
    "datelist.pop(0)\n",
    "datelist.pop(0)\n",
    "datelist.remove('Lookup')\n",
    "df1 = df1.loc[:,includelist]\n",
    "\n",
    "#Transpose and change index\n",
    "lookuplist = df1['Lookup'].to_list()\n",
    "df1 = df1.transpose()\n",
    "df1.columns = lookuplist\n",
    "df1 = df1.transpose()\n",
    "\n",
    "#Create a lookup list to loop over for maindf\n",
    "lookuplist = df1['Lookup'].value_counts().index.to_list()\n",
    "lookuplist = sorted(lookuplist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing main dataframe and write to bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lookup                 object\n",
      "state                  object\n",
      "county                 object\n",
      "FIPS                  float64\n",
      "population              int64\n",
      "date                   object\n",
      "confirmed               int64\n",
      "deaths                  int64\n",
      "date1          datetime64[ns]\n",
      "statecounty            object\n",
      "dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:57, 177.53s/it]\n"
     ]
    }
   ],
   "source": [
    "#Construction of maindf\n",
    "colnames = ['lookup','state','county','FIPS','population','date','confirmed','deaths']\n",
    "\n",
    "maindf = pd.DataFrame(index=range(0,len(lookuplist)*len(datelist)), columns=colnames)\n",
    "\n",
    "#Start loop for confirmed\n",
    "j = 0\n",
    "for i in lookuplist:\n",
    "    testdf = df.loc[i,:]\n",
    "    testdf1 = df1.loc[i,:]\n",
    "    \n",
    "    #Confirmed cases\n",
    "    timeseries = testdf[3:-1]\n",
    "    date = timeseries.index.to_list()\n",
    "    timeseries = timeseries.to_list()\n",
    "    length = len(timeseries)\n",
    "    \n",
    "    #Deaths\n",
    "    timeseries1 = testdf1[4:-1].to_list()\n",
    "    \n",
    "    maindf.iloc[j:(j+length),colnames.index('lookup')] = i\n",
    "    maindf.iloc[j:(j+length),colnames.index('state')] = testdf[2]\n",
    "    maindf.iloc[j:(j+length),colnames.index('county')] = testdf[1]\n",
    "    maindf.iloc[j:(j+length),colnames.index('FIPS')] = testdf[0]\n",
    "    maindf.iloc[j:(j+length),colnames.index('population')] = testdf1[3]\n",
    "    maindf.iloc[j:(j+length),colnames.index('date')] = date\n",
    "    maindf.iloc[j:(j+length),colnames.index('confirmed')] = timeseries\n",
    "    maindf.iloc[j:(j+length),colnames.index('deaths')] = timeseries1\n",
    "    j = j+length\n",
    "    \n",
    "maindf.loc[:,'date1'] = pd.to_datetime(maindf['date'],format='%m/%d/%y')\n",
    "maindf['lookup'] = maindf['lookup'] + maindf['date1'].astype(str).tolist()\n",
    "\n",
    "labels = maindf['lookup'].to_list()\n",
    "maindf = maindf.transpose()\n",
    "maindf.columns = labels\n",
    "maindf = maindf.transpose()\n",
    "maindf['statecounty'] = maindf['state'] + '-' + maindf['county']\n",
    "\n",
    "#converting datatypes \n",
    "maindf = maindf.infer_objects() \n",
    "print(maindf.dtypes)\n",
    "\n",
    "convert_dict = {'lookup': str, \n",
    "                'state': str,\n",
    "                'county': str}\n",
    "maindf = maindf.astype(convert_dict)\n",
    "\n",
    "#Remove some states\n",
    "maindf = maindf[~maindf['state'].isin(excludestate)]\n",
    "regionlst = maindf['state'].tolist()\n",
    "maindf['region'] = list(map(lambda x : 'US-'+rstatedict[x], regionlst))\n",
    "\n",
    "#Special cases for certain county\n",
    "maindf = maindf.replace('Dona Ana','Doña Ana')\n",
    "\n",
    "#Wrie to bigquery\n",
    "maindf.to_gbq('usprojections.temp_cases',if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update static cases table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 Query error: Inserted row has wrong column count; Has 15, expected 17 at [32:5]\n\n(job ID: a596a5db-2f06-49c1-a914-833e90375345)\n\n                                    -----Query Job SQL Follows-----                                     \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:    DELETE FROM `covid-jul25.usprojections.cases` WHERE True;\n   3:    INSERT INTO `covid-jul25.usprojections.cases`\n   4:    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.cases`;\n   5:    -- CREATE TABLE `covid-jul25.usprojections.cases`\n   6:    (SELECT * except(date,date1), date1 as date, '' as lat_long\n   7:    FROM `covid-jul25.usprojections.temp_cases`);\n   8:    \n   9:    DELETE FROM `covid-jul25.usprojections.final_cases` WHERE True;\n  10:    INSERT INTO `covid-jul25.usprojections.final_cases`\n  11:    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.final_cases`;\n  12:    -- CREATE TABLE `covid-jul25.usprojections.final_cases` AS\n  13:    SELECT *, deaths/population*1000 as death_per_1k, confirmed/population*1000 as confirmed_per_1k\n  14:    FROM\n  15:    (SELECT A.* except(lat_long),B.lat_long \n  16:    FROM `covid-jul25.usprojections.cases` as A\n  17:    JOIN `covid-jul25.usprojections.countyarea` as B\n  18:    ON A.statecounty = B.statecounty);\n  19:    \n  20:    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.cases_velocity`;\n  21:    -- CREATE TABLE `covid-jul25.usprojections.cases_velocity` AS\n  22:    DELETE FROM `covid-jul25.usprojections.cases_velocity` WHERE True;\n  23:    INSERT INTO `covid-jul25.usprojections.cases_velocity`\n  24:    SELECT *, confirmed/duration as confirmed_velocity, deaths/duration as deaths_velocity FROM\n  25:    (SELECT *, row_number() OVER(PARTITION BY statecounty ORDER BY date ASC) as duration\n  26:    FROM `covid-jul25.usprojections.final_cases`);\n  27:    \n  28:    DELETE FROM `covid-jul25.usprojections.latest_cases` WHERE True;\n  29:    INSERT INTO `covid-jul25.usprojections.latest_cases`\n  30:    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.latest_cases`;\n  31:    -- CREATE TABLE `covid-jul25.usprojections.latest_cases` AS\n  32:    SELECT * except(row),\n  33:    rank() OVER (ORDER BY death_per_1k DESC) death_rank,\n  34:    rank() OVER (ORDER BY confirmed_per_1k DESC) confirmed_rank\n  35:    FROM\n  36:    (SELECT *, row_number() OVER(PARTITION BY statecounty ORDER BY date DESC) row\n  37:    FROM `covid-jul25.usprojections.final_cases`)\n  38:    WHERE row = 1\n  39:    \n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-716381292b8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mWHERE\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \"\"\")\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Waits for job to complete.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\google\\cloud\\bigquery\\job.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, page_size, max_results, retry, timeout, start_index)\u001b[0m\n\u001b[0;32m   3205\u001b[0m         \"\"\"\n\u001b[0;32m   3206\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3207\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3209\u001b[0m             \u001b[1;31m# Return an iterator instead of returning the job.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\google\\cloud\\bigquery\\job.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, retry, timeout)\u001b[0m\n\u001b[0;32m    810\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m         \u001b[1;31m# TODO: modify PollingFuture so it can pass a retry argument to done().\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\google\\api_core\\future\\polling.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[1;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBadRequest\u001b[0m: 400 Query error: Inserted row has wrong column count; Has 15, expected 17 at [32:5]\n\n(job ID: a596a5db-2f06-49c1-a914-833e90375345)\n\n                                    -----Query Job SQL Follows-----                                     \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:    DELETE FROM `covid-jul25.usprojections.cases` WHERE True;\n   3:    INSERT INTO `covid-jul25.usprojections.cases`\n   4:    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.cases`;\n   5:    -- CREATE TABLE `covid-jul25.usprojections.cases`\n   6:    (SELECT * except(date,date1), date1 as date, '' as lat_long\n   7:    FROM `covid-jul25.usprojections.temp_cases`);\n   8:    \n   9:    DELETE FROM `covid-jul25.usprojections.final_cases` WHERE True;\n  10:    INSERT INTO `covid-jul25.usprojections.final_cases`\n  11:    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.final_cases`;\n  12:    -- CREATE TABLE `covid-jul25.usprojections.final_cases` AS\n  13:    SELECT *, deaths/population*1000 as death_per_1k, confirmed/population*1000 as confirmed_per_1k\n  14:    FROM\n  15:    (SELECT A.* except(lat_long),B.lat_long \n  16:    FROM `covid-jul25.usprojections.cases` as A\n  17:    JOIN `covid-jul25.usprojections.countyarea` as B\n  18:    ON A.statecounty = B.statecounty);\n  19:    \n  20:    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.cases_velocity`;\n  21:    -- CREATE TABLE `covid-jul25.usprojections.cases_velocity` AS\n  22:    DELETE FROM `covid-jul25.usprojections.cases_velocity` WHERE True;\n  23:    INSERT INTO `covid-jul25.usprojections.cases_velocity`\n  24:    SELECT *, confirmed/duration as confirmed_velocity, deaths/duration as deaths_velocity FROM\n  25:    (SELECT *, row_number() OVER(PARTITION BY statecounty ORDER BY date ASC) as duration\n  26:    FROM `covid-jul25.usprojections.final_cases`);\n  27:    \n  28:    DELETE FROM `covid-jul25.usprojections.latest_cases` WHERE True;\n  29:    INSERT INTO `covid-jul25.usprojections.latest_cases`\n  30:    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.latest_cases`;\n  31:    -- CREATE TABLE `covid-jul25.usprojections.latest_cases` AS\n  32:    SELECT * except(row),\n  33:    rank() OVER (ORDER BY death_per_1k DESC) death_rank,\n  34:    rank() OVER (ORDER BY confirmed_per_1k DESC) confirmed_rank\n  35:    FROM\n  36:    (SELECT *, row_number() OVER(PARTITION BY statecounty ORDER BY date DESC) row\n  37:    FROM `covid-jul25.usprojections.final_cases`)\n  38:    WHERE row = 1\n  39:    \n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |"
     ]
    }
   ],
   "source": [
    "#Update the static cases table\n",
    "query_job = bigquery_client.query(\n",
    "    \"\"\"\n",
    "    DELETE FROM `covid-jul25.usprojections.cases` WHERE True;\n",
    "    INSERT INTO `covid-jul25.usprojections.cases`\n",
    "    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.cases`;\n",
    "    -- CREATE TABLE `covid-jul25.usprojections.cases`\n",
    "    (SELECT * except(date,date1), date1 as date, '' as lat_long\n",
    "    FROM `covid-jul25.usprojections.temp_cases`);\n",
    "    \n",
    "    DELETE FROM `covid-jul25.usprojections.final_cases` WHERE True;\n",
    "    INSERT INTO `covid-jul25.usprojections.final_cases`\n",
    "    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.final_cases`;\n",
    "    -- CREATE TABLE `covid-jul25.usprojections.final_cases` AS\n",
    "    SELECT *, deaths/population*1000 as death_per_1k, confirmed/population*1000 as confirmed_per_1k\n",
    "    FROM\n",
    "    (SELECT A.* except(lat_long),B.lat_long \n",
    "    FROM `covid-jul25.usprojections.cases` as A\n",
    "    JOIN `covid-jul25.usprojections.countyarea` as B\n",
    "    ON A.statecounty = B.statecounty);\n",
    "    \n",
    "    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.cases_velocity`;\n",
    "    -- CREATE TABLE `covid-jul25.usprojections.cases_velocity` AS\n",
    "    DELETE FROM `covid-jul25.usprojections.cases_velocity` WHERE True;\n",
    "    INSERT INTO `covid-jul25.usprojections.cases_velocity`\n",
    "    SELECT *, confirmed/duration as confirmed_velocity, deaths/duration as deaths_velocity FROM\n",
    "    (SELECT *, row_number() OVER(PARTITION BY statecounty ORDER BY date ASC) as duration\n",
    "    FROM `covid-jul25.usprojections.final_cases`);\n",
    "    \n",
    "    DELETE FROM `covid-jul25.usprojections.latest_cases_temp` WHERE True;\n",
    "    INSERT INTO `covid-jul25.usprojections.latest_cases_temp`\n",
    "    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.latest_cases`;\n",
    "    -- CREATE TABLE `covid-jul25.usprojections.latest_cases` AS\n",
    "    SELECT * except(row),\n",
    "    rank() OVER (ORDER BY death_per_1k DESC) death_rank,\n",
    "    rank() OVER (ORDER BY confirmed_per_1k DESC) confirmed_rank\n",
    "    FROM\n",
    "    (SELECT *, row_number() OVER(PARTITION BY statecounty ORDER BY date DESC) row\n",
    "    FROM `covid-jul25.usprojections.final_cases`)\n",
    "    WHERE row = 1\n",
    "    \"\"\")\n",
    "results = query_job.result()  # Waits for job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|█████████████████████████████████████████████████████████████| 3135/3135 [00:00<00:00, 3699.79rows/s]\n",
      "1it [00:04,  4.43s/it]\n"
     ]
    }
   ],
   "source": [
    "#Read from latest_cases_temp table\n",
    "sql = \"\"\"\n",
    "    SELECT *\n",
    "    FROM [covid-jul25.usprojections.latest_cases_temp]\n",
    "    \"\"\"\n",
    "lastestcases = pd.read_gbq(sql, dialect='legacy')\n",
    "\n",
    "#Clear the latest_cases table\n",
    "query_job = bigquery_client.query(\n",
    "    \"\"\"DELETE FROM `covid-jul25.usprojections.latest_cases` WHERE True\"\"\")\n",
    "results = query_job.result()\n",
    "\n",
    "#Write to BigQuery\n",
    "lastestcases.to_gbq('usprojections.latest_cases',if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE MOBILITY DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create STATE temp table to hold updated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a STATE LEVEL table to hold the updated data\n",
    "query_job = bigquery_client.query(\n",
    "    \"\"\"\n",
    "    -- DROP TABLE IF EXISTS `covid-jul25.usprojections.mobility_state`;\n",
    "    -- CREATE TABLE `covid-jul25.usprojections.mobility_state` AS\n",
    "    DELETE FROM `covid-jul25.usprojections.mobility_state` WHERE True;\n",
    "    INSERT INTO `covid-jul25.usprojections.mobility_state`\n",
    "    #STATE LEVEL\n",
    "    SELECT *, CURRENT_TIMESTAMP() as mobility_update_time FROM\n",
    "    (SELECT sub_region_1 as state, sub_region_2 as county, iso_3166_2_code as region, * except(sub_region_1,sub_region_2,iso_3166_2_code) FROM `bigquery-public-data.covid19_google_mobility.mobility_report`\n",
    "    WHERE country_region_code = 'US'\n",
    "    AND sub_region_1 NOT IN ('American Samoa','United States Virgin Islands','Commonwealth of the Northern Mariana Islands','Guam','Puerto Rico')\n",
    "    AND sub_region_2 is null); #State level is null, county level is not null\n",
    "    \"\"\")\n",
    "results = query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Mobility construction for each type\n",
    "# mobilitylonglist = ['retail_and_recreation_percent_change_from_baseline','grocery_and_pharmacy_percent_change_from_baseline','parks_percent_change_from_baseline',\n",
    "# 'transit_stations_percent_change_from_baseline','workplaces_percent_change_from_baseline','residential_percent_change_from_baseline']\n",
    "# mobilityshortlist = ['retail & recreation','grocery & pharmacy','parks','transit','workplaces','residential']\n",
    "# mobilitytablelist = ['retail_recreation','grocery_pharmacy','parks','transit','workplaces','residential']\n",
    "\n",
    "# #dictionary with tablename as key and tuples of long and short name for values\n",
    "# mobilitydict = dict(zip(mobilitytablelist,zip(mobilitylonglist,mobilityshortlist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Looping through the tables\n",
    "# for key in mobilitydict:\n",
    "#     query_job = bigquery_client.query(\n",
    "#         f\"\"\"\n",
    "#         DROP TABLE IF EXISTS `covid-jul25.usprojections.mobility_{key}`;\n",
    "#         CREATE TABLE `covid-jul25.usprojections.mobility_{key}` AS\n",
    "#         #DELETE FROM `covid-jul25.usprojections.mobility_{key}` WHERE True;\n",
    "#         #INSERT INTO `covid-jul25.usprojections.mobility_{key}`\n",
    "#         SELECT state, region, date, mobility_update_time, {mobilitydict[key][0]} as %change from baseline, '{mobilitydict[key][1]}' as type\n",
    "#         FROM `covid-jul25.usprojections.mobility_state`\n",
    "#         \"\"\")\n",
    "#     results = query_job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = bigquery_client.query(\n",
    "    \"\"\"\n",
    "    -- DROP TABLE `covid-jul25.usprojections.mobility_arima_join`;\n",
    "    -- CREATE TABLE `covid-jul25.usprojections.mobility_arima_join` AS\n",
    "    DELETE FROM `covid-jul25.usprojections.mobility_arima_join` WHERE True;\n",
    "    INSERT INTO `covid-jul25.usprojections.mobility_arima_join`\n",
    "    (SELECT * except(iso_3166_2_code), iso_3166_2_code as region FROM `bigquery-public-data.covid19_google_mobility.mobility_report`\n",
    "    WHERE country_region_code = 'US'\n",
    "    AND sub_region_2 is null\n",
    "    AND iso_3166_2_code is not null)\n",
    "\"\"\")\n",
    "results = query_job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE STATIC STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.08rows/s]\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    #Static stats updated daily\n",
    "    SELECT avg(death_per_1k) as national_avg_death_per_1k,\n",
    "    avg(confirmed_per_1k) as national_avg_confirmed_per_1k\n",
    "    FROM [covid-jul25.usprojections.latest_cases]\n",
    "    \"\"\"\n",
    "staticstats = pd.read_gbq(sql, dialect='legacy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read rt latest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████████████████████| 51/51 [00:00<00:00, 151.74rows/s]\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    #Static stats updated daily\n",
    "    SELECT *\n",
    "    FROM [covid-jul25.usprojections.latest_rt_results]\n",
    "    \"\"\"\n",
    "rtstats = pd.read_gbq(sql, dialect='legacy')\n",
    "\n",
    "#Get only certain columns\n",
    "rtstats = rtstats[['region','mean','median','lower_80','upper_80']]\n",
    "rtstats.columns = ['region','rt_mean','rt_median','rt_lower_80','rt_upper_80']\n",
    "rtstats = rtstats.set_index('region')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read state mobility latest data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|█████████████████████████████████████████████████████████████| 9282/9282 [00:02<00:00, 4414.67rows/s]\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    #Static stats updated daily\n",
    "    SELECT *\n",
    "    FROM [covid-jul25.usprojections.mobility_state]\n",
    "    \"\"\"\n",
    "mobilitystats = pd.read_gbq(sql, dialect='legacy')\n",
    "\n",
    "mobilitylist = ['retail_and_recreation_percent_change_from_baseline', 'grocery_and_pharmacy_percent_change_from_baseline', 'parks_percent_change_from_baseline',\n",
    "'transit_stations_percent_change_from_baseline', 'workplaces_percent_change_from_baseline', 'residential_percent_change_from_baseline']\n",
    "mobilitystats = mobilitystats.sort_values(['region','date']).drop_duplicates(subset=['region'],keep='last')\n",
    "\n",
    "mobilitystats = mobilitystats.set_index('region')\n",
    "mobilitystats = mobilitystats[mobilitylist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct staticstatsdf on state level for static data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import from staticstats\n",
    "staticstatsdf = pd.DataFrame()\n",
    "staticstatsdf['region'] = list(countyarea['region'].unique())\n",
    "staticstatsdf['national_avg_death_per_1k'] = staticstats.loc[0,'national_avg_death_per_1k']\n",
    "staticstatsdf['national_avg_confirmed_per_1k'] = staticstats.loc[0,'national_avg_confirmed_per_1k']\n",
    "staticstatsdf['index'] = staticstatsdf['region']\n",
    "staticstatsdf = staticstatsdf.set_index('index')\n",
    "\n",
    "#Join with rt data\n",
    "staticstatsdf = staticstatsdf.join(rtstats, lsuffix='_caller', rsuffix='_other')\n",
    "\n",
    "#Join with mobility data\n",
    "staticstatsdf = staticstatsdf.join(mobilitystats, lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.13s/it]\n"
     ]
    }
   ],
   "source": [
    "#Clear table\n",
    "query_job = bigquery_client.query(\n",
    "    \"\"\"\n",
    "    DELETE FROM `covid-jul25.usprojections.latest_stats` WHERE True\n",
    "    \"\"\")\n",
    "results = query_job.result()\n",
    "\n",
    "#Write to BigQuery\n",
    "staticstatsdf.to_gbq('usprojections.latest_stats',if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE STATIC STATS FOR ARIMA NEXT 7 DAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read raw data from BigQuery\n",
    "sql = \"\"\"SELECT * FROM [covid-jul25.arimamodels.confirmed_US_forecast]\"\"\"\n",
    "rawconfirmeddf = pd.read_gbq(sql, dialect='legacy')\n",
    "\n",
    "sql = \"\"\"SELECT * FROM [covid-jul25.arimamodels.deaths_US_forecast]\"\"\"\n",
    "rawdeathsdf = pd.read_gbq(sql, dialect='legacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set today\n",
    "today = datetime.date.today()\n",
    "sd = today + datetime.timedelta(days=7) #7-day forecast\n",
    "#Set timezone to UTC\n",
    "sd = datetime.datetime(sd.year,sd.month,sd.day,tzinfo=datetime.timezone.utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIRMED cases next 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only counties in the countyarea list (EXCLUDE certain counties and territories)\n",
    "confirmeddf = rawconfirmeddf.copy()\n",
    "confirmeddf = confirmeddf[confirmeddf['statecounty'].isin(list(countyarea['statecounty']))]\n",
    "#Get data for 7 day from now and forecast_value\n",
    "confirmeddf = confirmeddf[confirmeddf['forecast_timestamp']==sd][['statecounty','forecast_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get state names using split\n",
    "state = list(map(lambda x:x.split('-',1),list(confirmeddf['statecounty'])))\n",
    "confirmeddf['state']=list(pd.DataFrame(state)[0])\n",
    "\n",
    "#Aggregate\n",
    "# statefc_confirmed = confirmeddf.groupby('state').sum()\n",
    "# statefc_confirmed['state']=statefc_confirmed.index #Set a state column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get state abbr\n",
    "stateabbr = list(map(lambda x:rstatedict[x],list(confirmeddf['state'])))\n",
    "statefc_confirmed = confirmeddf.copy()\n",
    "statefc_confirmed['region'] = list(pd.DataFrame(stateabbr)[0])\n",
    "statefc_confirmed['region'] = 'US-'+ statefc_confirmed['region']\n",
    "statefc_confirmed = statefc_confirmed.drop(columns=['state'])\n",
    "statefc_confirmed.columns = ['statecounty','confirmed_forecast','region']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEATHS cases next 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get only counties in the countyarea list (EXCLUDE certain counties and territories)\n",
    "deathsdf = rawdeathsdf.copy()\n",
    "deathsdf = deathsdf[deathsdf['statecounty'].isin(list(countyarea['statecounty']))]\n",
    "#Get data for 7 day from now and forecast_value\n",
    "deathsdf = deathsdf[deathsdf['forecast_timestamp']==sd][['statecounty','forecast_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get state names using split\n",
    "state = list(map(lambda x:x.split('-',1),list(deathsdf['statecounty'])))\n",
    "deathsdf['state']=list(pd.DataFrame(state)[0])\n",
    "\n",
    "#Aggregate\n",
    "# statefc_deaths = deathsdf.groupby('state').sum()\n",
    "# statefc_deaths['state']=statefc_deaths.index #Set a state column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get state abbr\n",
    "stateabbr = list(map(lambda x:rstatedict[x],list(deathsdf['state'])))\n",
    "statefc_deaths = deathsdf.copy()\n",
    "statefc_deaths['region'] = list(pd.DataFrame(stateabbr)[0])\n",
    "statefc_deaths['region'] = 'US-'+ statefc_deaths['region']\n",
    "statefc_deaths = statefc_deaths.drop(columns=['state'])\n",
    "statefc_deaths.columns = ['statecounty','deaths_forecast','region']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to BigQuery and Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to BigQuery\n",
    "statefc_confirmed.to_gbq('usprojections.arima_confirmed_statecounty',if_exists='replace')\n",
    "statefc_deaths.to_gbq('usprojections.arima_deaths_statecounty',if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update static stats\n",
    "query_job = bigquery_client.query(\n",
    "    \"\"\"\n",
    "    UPDATE `covid-jul25.usprojections.latest_cases` as M\n",
    "    SET M.arima_confirmed_forecast = S.confirmed_forecast\n",
    "    FROM `covid-jul25.usprojections.arima_confirmed_statecounty` as S\n",
    "    WHERE M.statecounty = S.statecounty;\n",
    "    \n",
    "    UPDATE `covid-jul25.usprojections.latest_cases` as M\n",
    "    SET M.arima_deaths_forecast = S.deaths_forecast\n",
    "    FROM `covid-jul25.usprojections.arima_deaths_statecounty` as S\n",
    "    WHERE M.statecounty = S.statecounty;\n",
    "    \"\"\")\n",
    "results = query_job.result()  # Waits for job to complete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.306px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
